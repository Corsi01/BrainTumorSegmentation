# -*- coding: utf-8 -*-
"""6 - 2DUnet_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/102EL-rEo72oE9_kybF6gjk-_XtV-USG2
"""

!pip install tensorflow==2.16.0rc0
!PYTHONHASHSEED=0
!pip install patchify

# Import other modules
from matplotlib import pyplot as plt
import zipfile
from shutil import copyfile
from time import time
import numpy as np
import pandas as pd
import random as python_random
import os
import shutil
import glob
from patchify import patchify, unpatchify
import random

# Import TensorFlow/Keras
import tensorflow as tf
import keras
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, MaxPooling3D, concatenate, Dropout, Activation, BatchNormalization, GroupNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import tensorflow.keras.backend as K


from google.colab import drive
drive.mount('/content/drive')

# Percorso del file ZIP su Google Drive
drive_zip_path = '/content/drive/MyDrive/DL_PROJECT/Data/Test_128.zip'
local_extract_path = '/content/Test_Data'
os.makedirs(local_extract_path, exist_ok=True)

# Decomprimere il file ZIP nella directory locale
with zipfile.ZipFile(drive_zip_path, 'r') as zip_ref:
    zip_ref.extractall(local_extract_path)

print("DecompressioneÂ completata.")

import numpy as np  # Import the numpy library for array manipulation

# Function to load images from a given directory and list of image file names
def load_img(img_dir, img_list):
    images = []  # Initialize an empty list to store the images
    for image_name in img_list:  # Loop through each image name in the list
        if image_name.split('.')[-1] == 'npy':  # Check if the file is a .npy file
            volume = np.load(img_dir + image_name)  # Load the .npy file as a numpy array
            # Extract 128 images along the third axis (z-axis) from each volume
            for j in range(volume.shape[2]):
                images.append(volume[:, :, j, :])  # Append each slice to the images list
    images = np.array(images)  # Convert the list of images to a numpy array
    return images  # Return the numpy array of images

# Generator function to load and yield image and mask batches
def image_loader(img_dir, img_list, mask_dir, mask_list, batch_size=256):
    assert batch_size == 256, "Batch size must be 256 to match the number of slices per two volumes."  # Ensure batch size is 256

    L = len(img_list)  # Get the length of the image list

    while True:  # Infinite loop to keep yielding batches
        for i in range(0, L, 2):  # Iterate through the image list in steps of 2
            if i + 1 < L:  # Check if there are at least two more volumes to load
                img = load_img(img_dir, [img_list[i], img_list[i+1]])  # Load images from two volumes
                mask = load_img(mask_dir, [mask_list[i], mask_list[i+1]])  # Load corresponding masks

                # Combine images and masks into a list of tuples and shuffle them
                combined = list(zip(img, mask))
                np.random.shuffle(combined)
                img[:], mask[:] = zip(*combined)  # Unzip the shuffled list back into images and masks

                yield (img, mask)  # Yield the shuffled images and masks as a batch
            else:
                # Handle the case where there is an odd number of volumes
                img = load_img(img_dir, [img_list[i]])  # Load images from the last volume
                mask = load_img(mask_dir, [mask_list[i]])  # Load corresponding masks

                # Combine images and masks into a list of tuples and shuffle them
                combined = list(zip(img, mask))
                np.random.shuffle(combined)
                img[:], mask[:] = zip(*combined)  # Unzip the shuffled list back into images and masks

                yield (img, mask)  # Yield the shuffled images and masks as a batch

import tensorflow.keras.backend as K

def DiceCoefficient(y_true, y_pred, smooth = 1e-6):

    y_pred = tf.keras.activations.softmax(y_pred, axis = -1)

    # Cast to float32 datatype
    y_true = K.cast(y_true, 'float32')
    y_pred = K.cast(y_pred, 'float32')

    # Flatten label and prediction tensors
    inputs = K.flatten(y_pred)
    targets = K.flatten(y_true)

    intersection = K.sum(inputs * targets)
    dice = (2 * intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)
    return dice

model = keras.saving.load_model('/content/drive/MyDrive/DL_PROJECT/2D_FINAL/64_Base.keras', compile = True , custom_objects={'DiceCoefficient' : DiceCoefficient})

model.summary()

test_img_dir = '/content/Test_Data/X_test/'
test_mask_dir = '/content/Test_Data/Y_test/'

test_img_list = sorted(os.listdir(test_img_dir))
test_mask_list = sorted(os.listdir(test_mask_dir))

batch_size = 256

test_img_datagen = image_loader(test_img_dir, test_img_list, test_mask_dir, test_mask_list, batch_size)

steps_per_epoch = len(test_img_list)//2
print(steps_per_epoch)

evaluation = model.evaluate(
    test_img_datagen,
    verbose = 1,
    steps = steps_per_epoch,
    callbacks = None,
    return_dict = True
)

evaluation