# -*- coding: utf-8 -*-
"""7 - 2DUnet_DeployOnOriginalVolumes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RJVme__Z8ij9zfkM7StPfMi5oeXfCCcd
    ###
"""

!pip install tensorflow==2.16.0rc0
!PYTHONHASHSEED=0
!pip install patchify

# Import other modules
from matplotlib import pyplot as plt
import zipfile
from shutil import copyfile
from time import time
import numpy as np
import pandas as pd
import random as python_random
import os
import shutil
import glob
from patchify import patchify, unpatchify
import random

# Import TensorFlow/Keras
import tensorflow as tf
import keras
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, MaxPooling3D, concatenate, Dropout, Activation, BatchNormalization, GroupNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import tensorflow.keras.backend as K


from google.colab import drive
drive.mount('/content/drive')

import tensorflow.keras.backend as K

def DiceCoefficient(y_true, y_pred, smooth = 1e-6):

    y_pred = tf.keras.activations.softmax(y_pred, axis = -1)

    # Cast to float32 datatype
    y_true = K.cast(y_true, 'float32')
    y_pred = K.cast(y_pred, 'float32')

    # Flatten label and prediction tensors
    inputs = K.flatten(y_pred)
    targets = K.flatten(y_true)

    intersection = K.sum(inputs * targets)
    dice = (2 * intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)
    return dice

model = keras.saving.load_model('/content/drive/MyDrive/DL_PROJECT/2D_FINAL/64_Base.keras', compile = True , custom_objects={'DiceCoefficient' : DiceCoefficient})

model.summary()

vol = np.load('/content/drive/MyDrive/DL_PROJECT/Data/image_006.npy')
mask = np.load('/content/drive/MyDrive/DL_PROJECT/Data/mask_006.npy')

def extract_images(volume):

  images = []

  for j in range(volume.shape[2]):
    images.append(volume[:, :, j, :])  # Append each slice to the images list

  images = np.array(images)

  return images

def patches_to_minibatch(patch):

  minibatch = []

  for x in range(patch.shape[0]):

    for y in range(patch.shape[1]):

      minibatch.append(patch[x , y, 0, :, :, :])

  return np.array(minibatch)

def reco_from_minibatch(minibatch):

  pre_unpatch = np.zeros(shape = (2, 2, 1, 128, 128, 4))

  pre_unpatch[0, 0, 0, :, :, :] = minibatch[0, :, :, :]
  pre_unpatch[0, 1, 0, :, :, :] = minibatch[1, :, :, :]
  pre_unpatch[1, 0, 0, :, :, :] = minibatch[2, :, :, :]
  pre_unpatch[1, 1, 0, :, :, :] = minibatch[3, :, :, :]


  return pre_unpatch

def make_prediction_vol(images):

  vol_pred = []

  for slice in range(images.shape[0]):

    patches = patchify(images[slice, :, :, :], (128, 128, 4), step = 128)

    batch = patches_to_minibatch(patches)

    pred_batch = model.predict(batch, verbose = 0)

    pre_unpatch = reco_from_minibatch(pred_batch)

    reco_img = unpatchify(pre_unpatch, (256, 256, 4))

    img_pred = list(reco_img.argmax(axis = 2))

    vol_pred.append(img_pred)

  return np.array(vol_pred)

images = extract_images(vol)
masks = extract_images(mask)

masks.shape

prediction = make_prediction_vol(images)

prediction.shape

true_vol = masks.argmax(axis = 3)
true_vol.shape

n_slice = random.randint(0, true_vol.shape[0])

fig, axs = plt.subplots(1, 2, figsize=(10, 10))

axs[0].imshow(prediction[n_slice, :, :], cmap = 'inferno')
axs[0].set_title('Predicted Segmentation')


axs[1].imshow(true_vol[n_slice, :, :], cmap = 'inferno')
axs[1].set_title('Original Segmentation')
